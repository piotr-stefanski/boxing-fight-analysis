{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import TensorFlow and other necessary libraries",
   "id": "ed51eec1d4760535"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model"
   ],
   "id": "517e2c53305fe787",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test GPU support",
   "id": "198784991f672fee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "\n",
    "tf.config.list_physical_devices()"
   ],
   "id": "b88f10db5b85d068",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get data, training and evaluating ",
   "id": "afd5e18ca081ee85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BASE_DIR_WITH_DATA = 'data/annotated_images/segmented_frames'\n",
    "\n",
    "def get_data_augmentation_layers(img_size):\n",
    "    return keras.Sequential(\n",
    "      [\n",
    "        layers.RandomFlip(\"horizontal\", input_shape=(img_size[0], img_size[1], 3)),\n",
    "        layers.RandomZoom(0.2),\n",
    "        layers.RandomContrast(0.2),\n",
    "      ]\n",
    "    )\n",
    "\n",
    "def normalize_and_prefetch_data(train_ds, val_ds, data_augmentation_layers=None):\n",
    "    #normalize data\n",
    "    normalization_layer = layers.Rescaling(1./255)\n",
    "    train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    print('normalized')\n",
    "\n",
    "    #cache data\n",
    "    train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    print('cached')\n",
    "\n",
    "    if data_augmentation_layers is not None:\n",
    "        train_ds = train_ds.map(lambda x, y: (data_augmentation_layers(x), y))\n",
    "        print('augumented train ds')\n",
    "\n",
    "    return train_ds, val_ds\n",
    "\n",
    "def get_data(img_size=(64, 64), augment_data_during_loading=False):\n",
    "    print(f'get data for approach: {approach_name}')\n",
    "    seed = np.random.randint(1e6)\n",
    "    data_dir = pathlib.Path(f'{BASE_DIR_WITH_DATA}/{approach_name}')\n",
    "\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "      data_dir,\n",
    "      validation_split=0.2,\n",
    "      subset=\"training\",\n",
    "      shuffle=True,\n",
    "      seed=seed,\n",
    "      image_size=img_size,\n",
    "      batch_size=batch_size)\n",
    "\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "      data_dir,\n",
    "      validation_split=0.2,\n",
    "      subset=\"validation\",\n",
    "      shuffle=True,\n",
    "      seed=seed,\n",
    "      image_size=img_size,\n",
    "      batch_size=batch_size)\n",
    "\n",
    "    if augment_data_during_loading:\n",
    "        return normalize_and_prefetch_data(train_ds, val_ds, get_data_augmentation_layers(img_size))\n",
    "\n",
    "    return normalize_and_prefetch_data(train_ds, val_ds)\n",
    "\n",
    "def get_model(type='cnn', img_size=(64, 64), num_classes=2):\n",
    "    data_augmentation = get_data_augmentation_layers(img_size)\n",
    "\n",
    "    if type == 'cnn':\n",
    "        model = Sequential([\n",
    "            data_augmentation,\n",
    "            layers.Conv2D(int(img_size[0]/2), (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(img_size[0], (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(img_size[0], (3, 3), activation='relu'),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(img_size[0], activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid', name='outputs')\n",
    "        ])\n",
    "    elif type == 'vgg16':\n",
    "        base_model = tf.keras.applications.vgg16.VGG16(\n",
    "            include_top=False,\n",
    "            weights=None,\n",
    "            input_shape=(img_size[0], img_size[1], 3),\n",
    "        )\n",
    "        x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "        predictions = layers.Dense(1, activation='sigmoid')(x) # Add a fully connected layer with a sigmoid activation for binary classification\n",
    "        model = Model(inputs=base_model.input, outputs=predictions) # Create the final model\n",
    "    elif type == 'inception':\n",
    "        base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "            include_top=False,\n",
    "            weights=None,\n",
    "            input_shape=(img_size[0], img_size[1], 3),\n",
    "        )\n",
    "        x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "        predictions = layers.Dense(1, activation='sigmoid')(x) # Add a fully connected layer with a sigmoid activation for binary classification\n",
    "        model = Model(inputs=base_model.input, outputs=predictions) # Create the final model\n",
    "    elif type == 'resnet':\n",
    "        base_model = tf.keras.applications.ResNet50(\n",
    "            include_top=False,\n",
    "            weights=None,\n",
    "            input_shape=(img_size[0], img_size[1], 3),\n",
    "        )\n",
    "\n",
    "        x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "        predictions = layers.Dense(1, activation='sigmoid')(x) # Add a fully connected layer with a sigmoid activation for binary classification\n",
    "        model = Model(inputs=base_model.input, outputs=predictions) # Create the final model\n",
    "\n",
    "    else:\n",
    "        raise Exception('wrong type of model')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(train_ds, val_ds, epochs = 30, img_size=(64, 64), num_classes=2, model_type='cnn', model=None):\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', verbose=1, patience=3)\n",
    "\n",
    "    if model is None:\n",
    "        model = get_model(type=model_type, img_size=img_size, num_classes=num_classes)\n",
    "\n",
    "        #compile and summary model\n",
    "        model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "        model.summary()\n",
    "\n",
    "    #compute class weights\n",
    "    data_dir = pathlib.Path(f'{BASE_DIR_WITH_DATA}/{approach_name}')\n",
    "    total = len(list(glob.glob(f'{data_dir}/*/*.jpg')))\n",
    "    neg = len(list(glob.glob(f'{data_dir}/punch/*.jpg')))\n",
    "    pos = len(list(glob.glob(f'{data_dir}/not_punch/*.jpg')))\n",
    "    weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "    weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "    print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "\n",
    "    #train model\n",
    "    history = model.fit(\n",
    "      train_ds,\n",
    "      validation_data=val_ds,\n",
    "      epochs=epochs,\n",
    "      class_weight=class_weight,\n",
    "      callbacks=[early_stopping_callback]\n",
    "    )\n",
    "\n",
    "    return history, model\n",
    "\n",
    "def evaluate_model(val_ds, model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for batch_images, batch_labels in val_ds:\n",
    "        predictions = model.predict(batch_images, verbose=0)\n",
    "        y_pred = y_pred + np.argmax(tf.nn.softmax(predictions), axis=1).tolist()\n",
    "        y_true = y_true + batch_labels.numpy().tolist()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    # print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "def evaluate_binary_model(val_ds, model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for batch_images, batch_labels in val_ds:\n",
    "        predictions = model.predict(batch_images, verbose=0)\n",
    "        y_pred_batch = (predictions > 0.5).astype('int32').flatten()\n",
    "        y_pred = y_pred + y_pred_batch.tolist()\n",
    "        y_true = y_true + batch_labels.numpy().tolist()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "def visualize_training_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs_range = range(len(acc))\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "    \n",
    "def train_and_evaluate(img_size, model_type):\n",
    "    train_ds, val_ds = get_data(img_size=img_size, augment_data_during_loading=model_type != 'cnn')\n",
    "    history, model = train_model(train_ds, val_ds, epochs=epochs, img_size=img_size, model_type=model_type)\n",
    "    tn, fp, fn, tp = evaluate_binary_model(val_ds, model)\n",
    "    \n",
    "    return history"
   ],
   "id": "a9b029c62d40b94d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## To reproduce\n",
    "1. Run above cell with function definitions.\n",
    "2. Define the approach in which you want to train classifier by setting value on `approach_name` variable.\n",
    "Possible values of `approach_name` variable: `original`, `extract_colours`, `background_subtraction_by_mog2`, `background_subtraction_by_knn`, `hybrid_extraction` and `speed_movement_extraction_{compare_with_n_back_frame}` (where `compare_with_n_back_frame` is variable to set).\n",
    "3. Run above cell to start training and evaluating classifier.\n",
    "\n",
    "**Remember**: in order to train classifier in a specific approach, you are need to prepare dataset for this approach using `preprocess_frames_before_classification.py` algorithm.\n",
    "\n",
    "PS you can try to train the classifier on another type of model, to do this change `model_type` parameter, possible values: `cnn`(custom structure) `vgg16`, `inception`(inceptionv3), `resnet`(resnet50). "
   ],
   "id": "e8e76a0d0e4471ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epochs = 80\n",
    "batch_size = 512\n",
    "approach_name = 'original'\n",
    "\n",
    "training_history = train_and_evaluate(img_size=(80, 80), model_type='cnn')\n",
    "visualize_training_history(training_history)"
   ],
   "id": "fe7489e504571ed3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
